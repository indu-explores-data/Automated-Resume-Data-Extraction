{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6ebf95d-f6fd-47dd-8689-e86fdbeb7917",
   "metadata": {},
   "source": [
    "## **Automated Resume Data Extraction (Name, Email and Phone Numbers) using NLP**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159b6e4d-2f8a-4a72-979f-3603b2f6be1c",
   "metadata": {},
   "source": [
    "### Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67194e9-f988-4c54-a7f6-66d97eae3081",
   "metadata": {},
   "source": [
    "In todayâ€™s competitive job market, organizations receive thousands of resumes for various job openings. These resumes often come in unstructured formats (text, Word, PDF), making it challenging to extract and organize candidate details efficiently. Manually scanning and processing this information is time-consuming, error-prone, and not scalable.  \n",
    "\n",
    "The objective of this project is to develop an automated **Named Entity Recognition (NER) system** capable of identifying and extracting key candidate information such as **Name, Email Address, and Phone Number** from resumes in different formats. By leveraging Natural Language Processing (NLP) techniques, this system will streamline the resume screening process, improve data organization, and serve as a foundation for building intelligent recruitment solutions.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982fc171-6e61-4570-a3d6-17de2fdee38a",
   "metadata": {},
   "source": [
    "### Step 1: Install Required Libraries and SpaCy Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ab973c03-9052-4f1a-bb7a-a247092b59e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\abhis\\anaconda3\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: spacy in c:\\users\\abhis\\anaconda3\\lib\\site-packages (3.8.7)\n",
      "Requirement already satisfied: python-docx in c:\\users\\abhis\\anaconda3\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: PyPDF2 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (3.0.1)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\abhis\\anaconda3\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from pandas) (2.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from spacy) (1.0.13)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from spacy) (3.0.10)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from spacy) (8.3.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from spacy) (2.10.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from spacy) (80.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from spacy) (24.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.1)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.4.26)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.3.0.post1)\n",
      "Requirement already satisfied: wrapt in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.0)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from python-docx) (5.3.0)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\abhis\\anaconda3\\lib\\site-packages (from jinja2->spacy) (3.0.2)\n",
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ----------- ---------------------------- 3.7/12.8 MB 19.7 MB/s eta 0:00:01\n",
      "     ------------------- -------------------- 6.3/12.8 MB 16.1 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 8.9/12.8 MB 15.2 MB/s eta 0:00:01\n",
      "     ----------------------------------- --- 11.8/12.8 MB 14.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 13.9 MB/s  0:00:00\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "# Install required packages (run once)\n",
    "!pip install pandas spacy python-docx PyPDF2 openpyxl\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28110f91-f682-4936-98fd-981edf037dba",
   "metadata": {},
   "source": [
    "### Step 2: Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "377255b9-5998-44d2-a3bb-ad1576c93a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from docx import Document\n",
    "from PyPDF2 import PdfReader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121a9f35-74dc-4f86-bc83-f28987047ab3",
   "metadata": {},
   "source": [
    "### Step 3: Load NLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "068c3775-00bf-416b-a1ae-be46b5651a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained small English NLP model from spaCy \n",
    "# (used for tokenization, POS tagging, and Named Entity Recognition)\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca76f49-2895-4aaa-9834-0eadaa87aa02",
   "metadata": {},
   "source": [
    "### Step 4: Directory containing resumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a4981035-cd3e-4960-8436-1b7e35f0916e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the folder where all resume files (PDF/DOCX/Word) are stored\n",
    "resume_dir = \"Resumes formats\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdbfbed-b836-4300-91d5-3a59ec327f5a",
   "metadata": {},
   "source": [
    "### Step 5: Regular Expression Patterns for Extracting Contact Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ca3ee6d4-0cd3-4d4f-96c5-3abca109adbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regex patterns\n",
    "name_pattern = re.compile(\n",
    "    r\"\\b(?!Curriculum Vitae|Resume|RESUME|C.V.|Name|Full Name)[A-Z][a-zA-Z]+(?:\\s[A-Z][a-zA-Z]+){0,2}\\b\"\n",
    ")\n",
    "\n",
    "phone_pattern = re.compile(r'(\\+?\\d{1,3}[-.\\s]?)?(\\d{10}|\\d{3}[-.\\s]\\d{3}[-.\\s]\\d{4})')\n",
    "email_pattern = re.compile(r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc2926c-1e24-4c57-9559-9e043bb54e01",
   "metadata": {},
   "source": [
    "### Step 6: Function to Clean Extracted Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "925bc5b7-5f8d-4ebc-969f-b3fbd10b2409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function removes extra spaces, newlines, and common labels from a name string\n",
    "\n",
    "def clean_name(name):\n",
    "    # Remove newlines, tabs, and extra spaces\n",
    "    name = re.sub(r'\\s+', ' ', name).strip()\n",
    "    # Remove common labels\n",
    "    name = re.sub(r'\\b(Name|Full Name|Email|E-mail|Phone|Contact)\\b', '', name, flags=re.IGNORECASE).strip()\n",
    "    return name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4404295-543c-48e8-835e-9f413ac4bfc7",
   "metadata": {},
   "source": [
    "### Step 7: Functions to Extract Text and Contact Details from Resumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ce57e7f9-0a3d-449d-9896-9155591cee37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. extract_text_from_file: Reads text content from .txt, .pdf, and .docx files\n",
    "# 2. extract_details: Extracts name, phone number, and email using regex and spaCy NER\n",
    "\n",
    "# Function to read text from files\n",
    "def extract_text_from_file(filepath):\n",
    "    ext = os.path.splitext(filepath)[1].lower()\n",
    "    text = \"\"\n",
    "    if ext == \".txt\":\n",
    "        with open(filepath, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "            text = f.read()\n",
    "    elif ext == \".pdf\":\n",
    "        reader = PdfReader(filepath)\n",
    "        for page in reader.pages:\n",
    "            if page.extract_text():\n",
    "                text += page.extract_text() + \"\\n\"\n",
    "    elif ext == \".docx\":\n",
    "        doc = Document(filepath)\n",
    "        text = \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "    return text\n",
    "\n",
    "# Function to extract details\n",
    "# More robust regex for phone numbers\n",
    "phone_pattern = re.compile(\n",
    "    r'(?:\\+?\\d{1,3}[-.\\s]?)?(?:\\(?\\d{2,4}\\)?[-.\\s]?){1,3}\\d{3,4}[-.\\s]?\\d{3,4}'\n",
    ")\n",
    "\n",
    "def extract_details(text):\n",
    "    # Extract phone numbers\n",
    "    phone_matches = phone_pattern.findall(text)\n",
    "    phones = []\n",
    "    for p in phone_matches:\n",
    "        # Keep only numbers with at least 10 digits total\n",
    "        digits = re.sub(r'\\D', '', p)\n",
    "        if len(digits) >= 10:\n",
    "            phones.append(p.strip())\n",
    "    phone = \", \".join(sorted(set(phones)))\n",
    "\n",
    "    # Extract emails\n",
    "    email_matches = email_pattern.findall(text)\n",
    "    email = \", \".join(sorted(set(email_matches))) if email_matches else \"\"\n",
    "\n",
    "    # Extract name\n",
    "    name_match = name_pattern.search(text)\n",
    "    if name_match:\n",
    "        name = clean_name(name_match.group())\n",
    "    else:\n",
    "        doc = nlp(text)\n",
    "        name = \"\"\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ == \"PERSON\" and len(ent.text.split()) <= 3:\n",
    "                name = ent.text.strip()\n",
    "                break\n",
    "\n",
    "    return name, phone, email\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c965684-6cad-461e-a1d8-e4dc04e7c7ef",
   "metadata": {},
   "source": [
    "### Step 8: Process Resumes and Extract Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "93a5c0ad-50f7-4401-920c-83d3acb3859d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all resumes\n",
    "# Iterates through all resume files in the directory, extracts text, and retrieves name, phone, and email\n",
    "\n",
    "data = []\n",
    "for file in os.listdir(resume_dir):\n",
    "    if file.lower().endswith(('.txt', '.pdf', '.docx')):\n",
    "        path = os.path.join(resume_dir, file)\n",
    "        text = extract_text_from_file(path)\n",
    "        name, phone, email = extract_details(text)\n",
    "        data.append({\"File\": file, \"Name\": name, \"Phone\": phone, \"Email\": email})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218ae22f-db8b-4479-b880-135db5e97138",
   "metadata": {},
   "source": [
    "### Step 9: Save Extracted Resume Details to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cc962c87-3ffc-453c-9ad6-017b4ae2a228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction completed. Data saved to 'Output_Resume_details.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "# Save to Excel\n",
    "df = pd.DataFrame(data)\n",
    "df.to_excel(\"Output_Resume_details.xlsx\", index=False)\n",
    "\n",
    "print(\"Extraction completed. Data saved to 'Output_Resume_details.xlsx'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fbb672-fa23-458d-a599-106aef587d8e",
   "metadata": {},
   "source": [
    "### Step 10: Display Extracted Resume Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1457a3ac-d3cd-4958-a4f0-5c9febe46cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            File             Name            Phone                      Email\n",
      "0   resume_1.txt      Aarav Mehta   +91-9988776655    aarav.mehta23@gmail.com\n",
      "1  resume_10.pdf       Hannah Lee   (917) 555-4421    hannah.lee23@icloud.com\n",
      "2   resume_2.txt    Sophia Turner  +1-646-555-0198  sophia.turner@outlook.com\n",
      "3   resume_3.txt      Rohan Gupta   +91-9123456789    rohan.gupta07@yahoo.com\n",
      "4   resume_4.txt     Emily Carter   (312) 555-2299   emily.carter12@gmail.com\n",
      "5  resume_5.docx       Arjun Nair   +91-9871122334  arjun.nair@protonmail.com\n",
      "6  resume_6.docx  Olivia Martinez  +1-213-555-7812   olivia.martinez@mail.com\n",
      "7  resume_7.docx      Karan Singh   +91-9812233445  karan.singh.dev@gmail.com\n",
      "8   resume_8.pdf    Grace Johnson  +1-408-555-1244  grace.johnson88@yahoo.com\n",
      "9   resume_9.pdf     Nikhil Verma   +91-9977886655   nikhil.verma@hotmail.com\n"
     ]
    }
   ],
   "source": [
    "# Shows the DataFrame containing names, phone numbers, and emails extracted from resumes\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010957c4-5428-4c51-915f-52f57b824713",
   "metadata": {},
   "source": [
    "\n",
    "### Project Insights: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e7d2e9-b983-49ea-b463-520574309036",
   "metadata": {},
   "source": [
    "\n",
    "1. **Automated Information Extraction**  \n",
    "   - The NER model successfully extracted **Name, Email, and Phone Number** from resumes across formats (TXT, DOCX, PDF).  \n",
    "   - This validates the ability of NLP to convert unstructured resume data into structured information.  \n",
    "\n",
    "2. **Format Independence**  \n",
    "   - The pipeline performed consistently across multiple formats.  \n",
    "   - This demonstrates that the solution is **robust and adaptable** to real-world resumes in varied file types.  \n",
    "\n",
    "3. **Improved Efficiency**  \n",
    "   - Manual resume screening is time-intensive.  \n",
    "   - Automation reduces effort, minimizes errors, and **accelerates candidate filtering**.  \n",
    "\n",
    "4. **Scalability**  \n",
    "   - The system can scale to process **large volumes of resumes** with minimal additional effort.  \n",
    "   - It also provides a foundation for extracting more complex details such as **skills, education, and job experience**.  \n",
    "\n",
    "5. **Practical Applicability**  \n",
    "   - The project illustrates a **real-world application of NLP in recruitment systems**.  \n",
    "   - Such a solution can be integrated into **Applicant Tracking Systems (ATS)** to enhance hiring efficiency.  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
